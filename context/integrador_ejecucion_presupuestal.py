# -*- coding: utf-8 -*-
"""integrador_ejecucion_presupuestal.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16Tit3z6hU4SVRt2_KG_GB16SVyUWDZcm

# **INTEGRACIÓN DATA EJECUCION PRESUPUESTAL 2024 A 2025**

Aquí integro todos los datos de la ejecución presupuestal obtenida de la página del Departamento Administrativo de Planeación Municipal, para poder cargarla a BigQuery de Google en el Bucket que cree.

## CREACIÓN DE VÍNCULO CON GOOGLE DRIVE
"""

### Configuración de enlace entre Colab y Google Drive
from google.colab import drive

drive.mount('/content/drive/')

"""## CARGA DE TODOS LOS ARCHIVOS ".csv" PARA LA CREACIÓN DE LOS DATAFRAMES POR ARCHIVO EN EL DICCIONARIO dfs"""

import os
import pandas as pd

# Define the directory path
directory_path = "/content/drive/MyDrive/INPUTS_DASH/DASHBOARD_PROYECTOS/EJECUCION_PRESUPUESTAL"

# List all files in the directory
files = os.listdir(directory_path)

# Filter for spreadsheet files (e.g., .csv or .xlsx)
spreadsheet_files = [f for f in files if f.endswith('.csv') or f.endswith('.xlsx')]

# Dictionary to store dataframes
dfs = {}

# Iterate through each spreadsheet file
for file_name in spreadsheet_files:
    file_path = os.path.join(directory_path, file_name)
    try:
        if file_name.endswith('.csv'):
            # Try reading with semicolon delimiter and skip bad lines
            df = pd.read_csv(file_path, sep=';', on_bad_lines='skip')
        elif file_name.endswith('.xlsx'):
            df = pd.read_excel(file_path)

        # Store the dataframe with the file name as the key (without extension)
        df_name = os.path.splitext(file_name)[0]
        dfs[df_name] = df
        print(f"Successfully loaded '{file_name}' into dataframe '{df_name}'")

    except Exception as e:
        print(f"Error loading '{file_name}': {e}")

"""## ELIMINACIÓN DE LA COLUMNA "RUBRO" DONDE CORRESPONDA"""

# Iterate through the dictionary of dataframes
for df_name, df in dfs.items():
    # Check if the column 'RUBRO' exists in the current dataframe
    if 'RUBRO' in df.columns:
        # If it exists, drop the column
        dfs[df_name] = df.drop(columns=['RUBRO'])
        print(f"Column 'RUBRO' dropped from dataframe '{df_name}'")
    else:
        print(f"Column 'RUBRO' not found in dataframe '{df_name}'")



"""## OBTENER LAS COLUMNAS DE TODOS LOS DATAFRAMES"""

# Collect all columns from all dataframes
all_columns_data = {}
for df_name, df in dfs.items():
  all_columns_data[df_name] = df.columns.tolist()

# Find the maximum number of columns across all dataframes
max_cols = max(len(cols) for cols in all_columns_data.values())

# Pad the column lists with None to ensure equal length for creating the DataFrame
padded_columns_data = {}
for df_name, cols in all_columns_data.items():
  padded_columns_data[df_name] = cols + [None] * (max_cols - len(cols))

# Create a new DataFrame from the padded column lists
columns_df = pd.DataFrame(padded_columns_data)

# Display the resulting DataFrame
print("\nUnified table of all columns from all dataframes:")
columns_df

if 'PROGRAMA' in dfs['EJECUCION_FEBRERO_2024'].columns:
  dfs['EJECUCION_FEBRERO_2024'] = dfs['EJECUCION_FEBRERO_2024'].drop(columns=['PROGRAMA'])
  print("Column 'programa' dropped from dataframe 'EJECUCION_FEBRERO_2024'")
else:
  print("Column 'programa' not found in dataframe 'EJECUCION_FEBRERO_2024'")

"""### NORMALIZACIÓN DE LAS COLUMNAS EN TODOS LOS DATAFRAMES"""

# Function to check if a column's first non-null value is '4599' (as int or string)
def is_program_column(column):
    # Find the first non-null value in the column
    first_value = column.dropna().iloc[0] if not column.dropna().empty else None

    # Check if the first value is 4599 (as int or string)
    return first_value is not None and (str(first_value) == '4599' or (isinstance(first_value, (int, float)) and first_value == 4599))

# Iterate through each dataframe in dfs
for df_name, df in dfs.items():
    columns_to_rename = {}
    # Iterate through each column in the current dataframe
    for col in df.columns:
        # Check if the column name is 'programa' or similar (case-insensitive and possibly with spaces)
        # And check if the first non-null value is 4599
        if 'programa' in col.lower().replace(" ", "") and is_program_column(df[col]):
            columns_to_rename[col] = 'cod_programa'

    # Rename the columns if any were found
    if columns_to_rename:
        dfs[df_name] = df.rename(columns=columns_to_rename)
        print(f"Renamed columns in dataframe '{df_name}': {columns_to_rename}")
    else:
        print(f"No columns meeting the criteria found in dataframe '{df_name}' for renaming.")

import re
import unicodedata

# Function to normalize column names
def normalize_column_names(columns):
    normalized_cols = []
    for col in columns:
        # Convert to lowercase
        col = col.lower()
        # Replace spaces with underscores
        col = col.replace(' ', '_')
        # Remove leading/trailing underscores
        col = col.strip('_')
        # Remove accents (tildes)
        col = unicodedata.normalize('NFD', col).encode('ascii', 'ignore').decode('utf-8')
        # Replace 'ñ' with 'n'
        col = col.replace('ñ', 'n')
        normalized_cols.append(col)
    return normalized_cols

# Apply the normalization function to column names of each dataframe in the dictionary
for df_name, df in dfs.items():
    df.columns = normalize_column_names(df.columns)
    dfs[df_name] = df
    print(f"Normalized columns for dataframe '{df_name}'")

# Optional: Display the normalized columns for verification
# Collect all normalized columns from all dataframes
normalized_all_columns_data = {}
for df_name, df in dfs.items():
  normalized_all_columns_data[df_name] = df.columns.tolist()

# Find the maximum number of columns across all dataframes
max_cols_normalized = max(len(cols) for cols in normalized_all_columns_data.values())

# Pad the column lists with None to ensure equal length for creating the DataFrame
padded_columns_data_normalized = {}
for df_name, cols in normalized_all_columns_data.items():
  padded_columns_data_normalized[df_name] = cols + [None] * (max_cols_normalized - len(cols))

# Create a new DataFrame from the padded column lists
normalized_columns_df = pd.DataFrame(padded_columns_data_normalized)

# Display the resulting DataFrame
print("\nUnified table of all normalized columns from all dataframes:")
normalized_columns_df

"""### FEATURE ENGINEERING"""

if 'programa' in dfs['EJECUCION_ENERO_2025'].columns:
  dfs['EJECUCION_ENERO_2025'] = dfs['EJECUCION_ENERO_2025'].drop(columns=['programa'])
  print("Column 'programa' dropped from dataframe 'EJECUCION_ENERO_2025'")
else:
  print("Column 'programa' not found in dataframe 'EJECUCION_ENERO_2025'")

if 'programa' in dfs['EJECUCION_FEBRERO_2025'].columns:
  dfs['EJECUCION_FEBRERO_2025'] = dfs['EJECUCION_FEBRERO_2025'].drop(columns=['programa'])
  print("Column 'programa' dropped from dataframe 'EJECUCION_FEBRERO_2025'")
else:
  print("Column 'programa' not found in dataframe 'EJECUCION_FEBRERO_2025'")

if 'programa' in dfs['EJECUCION_MARZO_2025'].columns:
  dfs['EJECUCION_MARZO_2025'] = dfs['EJECUCION_MARZO_2025'].drop(columns=['programa'])
  print("Column 'programa' dropped from dataframe 'EJECUCION_MARZO_2025'")
else:
  print("Column 'programa' not found in dataframe 'EJECUCION_MARZO_2025'")

if 'programa' in dfs['EJECUCION_ABRIL_2025'].columns:
  dfs['EJECUCION_ABRIL_2025'] = dfs['EJECUCION_ABRIL_2025'].drop(columns=['programa'])
  print("Column 'programa' dropped from dataframe 'EJECUCION_ABRIL_2025'")
else:
  print("Column 'programa' not found in dataframe 'EJECUCION_ABRIL_2025'")

if 'programa' in dfs['EJECUCION_MAYO_2025'].columns:
  dfs['EJECUCION_MAYO_2025'] = dfs['EJECUCION_MAYO_2025'].drop(columns=['programa'])
  print("Column 'programa' dropped from dataframe 'EJECUCION_MAYO_2025'")
else:
  print("Column 'programa' not found in dataframe 'EJECUCION_MAYO_2025'")

if 'programa' in dfs['EJECUCION_OCTUBRE_2024'].columns:
  dfs['EJECUCION_OCTUBRE_2024'] = dfs['EJECUCION_OCTUBRE_2024'].drop(columns=['programa'])
  print("Column 'programa' dropped from dataframe 'EJECUCION_OCTUBRE_2024'")
else:
  print("Column 'programa' not found in dataframe 'EJECUCION_OCTUBRE_2024'")

if 'programa' in dfs['EJECUCION_NOVIEMBRE_2024'].columns:
  dfs['EJECUCION_NOVIEMBRE_2024'] = dfs['EJECUCION_NOVIEMBRE_2024'].drop(columns=['programa'])
  print("Column 'programa' dropped from dataframe 'EJECUCION_NOVIEMBRE_2024'")
else:
  print("Column 'programa' not found in dataframe 'EJECUCION_NOVIEMBRE_2024'")

if 'programa' in dfs['EJECUCION_DICIEMBRE_2024'].columns:
  dfs['EJECUCION_DICIEMBRE_2024'] = dfs['EJECUCION_DICIEMBRE_2024'].drop(columns=['programa'])
  print("Column 'programa' dropped from dataframe 'EJECUCION_DICIEMBRE_2024'")
else:
  print("Column 'programa' not found in dataframe 'EJECUCION_DICIEMBRE_2024'")

# Iterar sobre cada dataframe en dfs
for df_name, df in dfs.items():
    columns_to_rename = {}
    # Iterar sobre cada columna en el dataframe actual
    for col in df.columns:
        # Verificar si el nombre de la columna es "programa"
        if col == "programa":
            columns_to_rename[col] = 'programa_presupuestal'
    # Renombrar las columnas si se encontraron coincidencias
    if columns_to_rename:
        dfs[df_name] = df.rename(columns=columns_to_rename)
        print(f"Columnas renombradas en el dataframe '{df_name}': {columns_to_rename}")
    else:
        print(f"No se encontró la columna 'programa' en el dataframe '{df_name}'.")

# Iterar sobre cada dataframe en dfs
for df_name, df in dfs.items():
    columns_to_rename = {}
    # Iterar sobre cada columna en el dataframe actual
    for col in df.columns:
        # Verificar si el nombre de la columna es "nombre_de_la_actividad"
        if col == "nombre_de_la_actividad":
            columns_to_rename[col] = 'nombre_actividad'

    # Renombrar las columnas si se encontraron coincidencias
    if columns_to_rename:
        dfs[df_name] = df.rename(columns=columns_to_rename)
        print(f"Columnas renombradas en el dataframe '{df_name}': {columns_to_rename}")
    else:
        print(f"No se encontró la columna 'nombre_de_la_actividad' en el dataframe '{df_name}'.")

# Iterar sobre cada dataframe en dfs
for df_name, df in dfs.items():
    columns_to_rename = {}
    # Iterar sobre cada columna en el dataframe actual
    for col in df.columns:
        # Verificar si el nombre de la columna es "nombre_de_fondo"
        if col == "nombre_de_fondo":
            columns_to_rename[col] = 'nombre_fondo'

    # Renombrar las columnas si se encontraron coincidencias
    if columns_to_rename:
        dfs[df_name] = df.rename(columns=columns_to_rename)
        print(f"Columnas renombradas en el dataframe '{df_name}': {columns_to_rename}")
    else:
        print(f"No se encontró la columna 'nombre_de_fondo' en el dataframe '{df_name}'.")

# Iterar sobre cada dataframe en dfs
for df_name, df in dfs.items():
    columns_to_rename = {}
    # Iterar sobre cada columna en el dataframe actual
    for col in df.columns:
        # Verificar si el nombre de la columna es "nombre_del_area_funcional"
        if col == "nombre_del_area_funcional":
            columns_to_rename[col] = 'nombre_area_funcional'

    # Renombrar las columnas si se encontraron coincidencias
    if columns_to_rename:
        dfs[df_name] = df.rename(columns=columns_to_rename)
        print(f"Columnas renombradas en el dataframe '{df_name}': {columns_to_rename}")
    else:
        print(f"No se encontró la columna 'nombre_del_area_funcional' en el dataframe '{df_name}'.")

# Iterar sobre cada dataframe en dfs
for df_name, df in dfs.items():
    columns_to_rename = {}
    # Iterar sobre cada columna en el dataframe actual
    for col in df.columns:
        # Verificar si el nombre de la columna es "nombre_de_linea_estrategica"
        if col == "nombre_de_linea_estrategica":
            columns_to_rename[col] = 'nombre_linea_estrategica'
    # Renombrar las columnas si se encontraron coincidencias
    if columns_to_rename:
        dfs[df_name] = df.rename(columns=columns_to_rename)
        print(f"Columnas renombradas en el dataframe '{df_name}': {columns_to_rename}")
    else:
        print(f"No se encontró la columna 'nombre_de_linea_estrategica' en el dataframe '{df_name}'.")

# Iterar sobre cada dataframe en dfs
for df_name, df in dfs.items():
    columns_to_rename = {}
    # Iterar sobre cada columna en el dataframe actual
    for col in df.columns:
        # Verificar si el nombre de la columna es "nombre_del_proyecto"
        if col == "nombre_del_proyecto":
            columns_to_rename[col] = 'nombre_proyecto'
    # Renombrar las columnas si se encontraron coincidencias
    if columns_to_rename:
        dfs[df_name] = df.rename(columns=columns_to_rename)
        print(f"Columnas renombradas en el dataframe '{df_name}': {columns_to_rename}")
    else:
        print(f"No se encontró la columna 'nombre_del_proyecto' en el dataframe '{df_name}'.")

# Iterar sobre cada dataframe en dfs
for df_name, df in dfs.items():
    columns_to_rename = {}
    # Iterar sobre cada columna en el dataframe actual
    for col in df.columns:
        # Verificar si el nombre de la columna es "tipo_de_gasto"
        if col == "tipo_de_gasto":
            columns_to_rename[col] = 'tipo_gasto'
    # Renombrar las columnas si se encontraron coincidencias
    if columns_to_rename:
        dfs[df_name] = df.rename(columns=columns_to_rename)
        print(f"Columnas renombradas en el dataframe '{df_name}': {columns_to_rename}")
    else:
        print(f"No se encontró la columna 'tipo_de_gasto' en el dataframe '{df_name}'.")

# Iterar sobre cada dataframe en dfs
for df_name, df in dfs.items():
    columns_to_rename = {}
    # Iterar sobre cada columna en el dataframe actual
    for col in df.columns:
        # Verificar si el nombre de la columna es "clasificacion_del_fondo"
        if col == "clasificacion_del_fondo":
            columns_to_rename[col] = 'clasificacion_fondo'
    # Renombrar las columnas si se encontraron coincidencias
    if columns_to_rename:
        dfs[df_name] = df.rename(columns=columns_to_rename)
        print(f"Columnas renombradas en el dataframe '{df_name}': {columns_to_rename}")
    else:
        print(f"No se encontró la columna 'clasificacion_del_fondo' en el dataframe '{df_name}'.")

# Iterar sobre cada dataframe en dfs
for df_name, df in dfs.items():
    columns_to_rename = {}
    # Iterar sobre cada columna en el dataframe actual
    for col in df.columns:
        # Verificar si el nombre de la columna es "ppto._disponible"
        if col == "ppto._disponible":
            columns_to_rename[col] = 'ppto_disponible'
    # Renombrar las columnas si se encontraron coincidencias
    if columns_to_rename:
        dfs[df_name] = df.rename(columns=columns_to_rename)
        print(f"Columnas renombradas en el dataframe '{df_name}': {columns_to_rename}")
    else:
        print(f"No se encontró la columna 'ppto._disponible' en el dataframe '{df_name}'.")

# Iterar sobre cada dataframe en dfs
for df_name, df in dfs.items():
    columns_to_rename = {}
    # Iterar sobre cada columna en el dataframe actual
    for col in df.columns:
        # Verificar si el nombre de la columna es "ppto._modificado"
        if col == "ppto._modificado":
            columns_to_rename[col] = 'ppto_modificado'
    # Renombrar las columnas si se encontraron coincidencias
    if columns_to_rename:
        dfs[df_name] = df.rename(columns=columns_to_rename)
        print(f"Columnas renombradas en el dataframe '{df_name}': {columns_to_rename}")
    else:
        print(f"No se encontró la columna 'ppto._modificado' en el dataframe '{df_name}'.")

# Iterar sobre cada dataframe en dfs
for df_name, df in dfs.items():
    columns_to_rename = {}
    # Iterar sobre cada columna en el dataframe actual
    for col in df.columns:
        # Verificar si el nombre de la columna es "fondo_1"
        if col == "fondo_1":
            columns_to_rename[col] = 'fondo'
    # Renombrar las columnas si se encontraron coincidencias
    if columns_to_rename:
        dfs[df_name] = df.rename(columns=columns_to_rename)
        print(f"Columnas renombradas en el dataframe '{df_name}': {columns_to_rename}")
    else:
        print(f"No se encontró la columna 'fondo_1' en el dataframe '{df_name}'.")

# Iterar sobre cada dataframe en dfs
for df_name, df in dfs.items():
    columns_to_rename = {}
    # Iterar sobre cada columna en el dataframe actual
    for col in df.columns:
        # Verificar si el nombre de la columna es "clasificacion_del_fondo_1"
        if col == "clasificacion_del_fondo_1":
            columns_to_rename[col] = 'clasificacion_fondo'
    # Renombrar las columnas si se encontraron coincidencias
    if columns_to_rename:
        dfs[df_name] = df.rename(columns=columns_to_rename)
        print(f"Columnas renombradas en el dataframe '{df_name}': {columns_to_rename}")
    else:
        print(f"No se encontró la columna 'clasificacion_del_fondo_1' en el dataframe '{df_name}'.")

# Iterar sobre cada dataframe en dfs
for df_name, df in dfs.items():
    columns_to_rename = {}
    # Iterar sobre cada columna en el dataframe actual
    for col in df.columns:
        # Verificar si el nombre de la columna es "pospre_1"
        if col == "pospre_1":
            columns_to_rename[col] = 'pospre'
    # Renombrar las columnas si se encontraron coincidencias
    if columns_to_rename:
        dfs[df_name] = df.rename(columns=columns_to_rename)
        print(f"Columnas renombradas en el dataframe '{df_name}': {columns_to_rename}")
    else:
        print(f"No se encontró la columna 'pospre_1' en el dataframe '{df_name}'.")

# Iterar sobre cada dataframe en dfs
for df_name, df in dfs.items():
    columns_to_rename = {}
    # Iterar sobre cada columna en el dataframe actual
    for col in df.columns:
        # Verificar si el nombre de la columna es "pospre_1.1"
        if col == "pospre_1.1":
            columns_to_rename[col] = 'nombre_pospre'
    # Renombrar las columnas si se encontraron coincidencias
    if columns_to_rename:
        dfs[df_name] = df.rename(columns=columns_to_rename)
        print(f"Columnas renombradas en el dataframe '{df_name}': {columns_to_rename}")
    else:
        print(f"No se encontró la columna 'pospre_1.1' en el dataframe '{df_name}'.")

# Iterar sobre cada dataframe en dfs
for df_name, df in dfs.items():
    columns_to_rename = {}
    # Iterar sobre cada columna en el dataframe actual
    for col in df.columns:
        # Verificar si el nombre de la columna es "nombre_de_dimension"
        if col == "nombre_de_dimension":
            columns_to_rename[col] = 'nombre_dimension'
    # Renombrar las columnas si se encontraron coincidencias
    if columns_to_rename:
        dfs[df_name] = df.rename(columns=columns_to_rename)
        print(f"Columnas renombradas en el dataframe '{df_name}': {columns_to_rename}")
    else:
        print(f"No se encontró la columna 'nombre_de_dimension' en el dataframe '{df_name}'.")

# Iterar sobre cada dataframe en dfs
for df_name, df in dfs.items():
    columns_to_rename = {}
    # Iterar sobre cada columna en el dataframe actual
    for col in df.columns:
        # Verificar si el nombre de la columna es "nombre_bp"
        if col == "nombre_bp":
            columns_to_rename[col] = 'nombre_proyecto'
    # Renombrar las columnas si se encontraron coincidencias
    if columns_to_rename:
        dfs[df_name] = df.rename(columns=columns_to_rename)
        print(f"Columnas renombradas en el dataframe '{df_name}': {columns_to_rename}")
    else:
        print(f"No se encontró la columna 'nombre_bp' en el dataframe '{df_name}'.")

# Iterar sobre cada dataframe en dfs
for df_name, df in dfs.items():
    columns_to_rename = {}
    # Iterar sobre cada columna en el dataframe actual
    for col in df.columns:
        # Verificar si el nombre de la columna es "nombre_bp"
        if col == "nompre_bp":
            columns_to_rename[col] = 'nombre_proyecto'
    # Renombrar las columnas si se encontraron coincidencias
    if columns_to_rename:
        dfs[df_name] = df.rename(columns=columns_to_rename)
        print(f"Columnas renombradas en el dataframe '{df_name}': {columns_to_rename}")
    else:
        print(f"No se encontró la columna 'nompre_bp' en el dataframe '{df_name}'.")

# Iterar sobre cada dataframe en dfs
for df_name, df in dfs.items():
    columns_to_rename = {}
    # Iterar sobre cada columna en el dataframe actual
    for col in df.columns:
        # Verificar si el nombre de la columna es "nombre_bp"
        if col == "nombre_de_programa":
            columns_to_rename[col] = 'nombre_programa'
    # Renombrar las columnas si se encontraron coincidencias
    if columns_to_rename:
        dfs[df_name] = df.rename(columns=columns_to_rename)
        print(f"Columnas renombradas en el dataframe '{df_name}': {columns_to_rename}")
    else:
        print(f"No se encontró la columna 'nombre_programa' en el dataframe '{df_name}'.")

# ELIMINAR COLUMNAS "producto_1"
for df_name, df in dfs.items():
    if 'producto_1' in df.columns:
        dfs[df_name] = df.drop(columns=['producto_1'])
        print(f"Columna 'producto_1' eliminada del dataframe '{df_name}'")
    else:
        print(f"Columna 'producto_1' no encontrada en el dataframe '{df_name}'")

# ELIMINAR COLUMNAS "programa.1"
for df_name, df in dfs.items():
    if 'programa.1' in df.columns:
        dfs[df_name] = df.drop(columns=['programa.1'])
        print(f"Columna 'programa.1' eliminada del dataframe '{df_name}'")
    else:
        print(f"Columna 'programa.1' no encontrada en el dataframe '{df_name}'")

# ELIMINAR COLUMNAS "sector"
for df_name, df in dfs.items():
    if 'sector' in df.columns:
        dfs[df_name] = df.drop(columns=['sector'])
        print(f"Columna 'sector' eliminada del dataframe '{df_name}'")
    else:
        print(f"Columna 'sector' no encontrada en el dataframe '{df_name}'")

# ELIMINAR COLUMNAS "cod_programa"
for df_name, df in dfs.items():
    if 'cod_programa' in df.columns:
        dfs[df_name] = df.drop(columns=['cod_programa'])
        print(f"Columna 'cod_programa' eliminada del dataframe '{df_name}'")
    else:
        print(f"Columna 'cod_programa' no encontrada en el dataframe '{df_name}'")

# ELIMINAR COLUMNAS "producto"
for df_name, df in dfs.items():
    if 'producto' in df.columns:
        dfs[df_name] = df.drop(columns=['producto'])
        print(f"Columna 'producto' eliminada del dataframe '{df_name}'")
    else:
        print(f"Columna 'producto' no encontrada en el dataframe '{df_name}'")

# ELIMINAR COLUMNAS "validador_cuipo"
for df_name, df in dfs.items():
    if 'validador_cuipo' in df.columns:
        dfs[df_name] = df.drop(columns=['validador_cuipo'])
        print(f"Columna 'validador_cuipo' eliminada del dataframe '{df_name}'")
    else:
        print(f"Columna 'validador_cuipo' no encontrada en el dataframe '{df_name}'")

# Crear un dataframe de referencia con las columnas 'bpin', 'dimension' y 'nombre_dimension'
# Se asume que al menos uno de los dataframes tiene estas columnas y son consistentes.
# Se toma el primer dataframe que tenga ambas columnas como referencia.
reference_df = None
for df in dfs.values():
    if 'bpin' in df.columns and 'dimension' in df.columns and 'nombre_dimension' in df.columns:
        reference_df = df[['bpin', 'dimension', 'nombre_dimension']].drop_duplicates().dropna(subset=['bpin']).set_index('bpin')
        print("DataFrame de referencia creado con éxito.")
        break

if reference_df is None:
    print("No se encontró un dataframe con las columnas 'bpin', 'dimension' y 'nombre_dimension'. No se puede completar la tarea.")
else:
    # Iterar sobre cada dataframe en dfs
    for df_name, df in dfs.items():
        # Verificar si las columnas 'dimension' y 'nombre_dimension' existen
        if 'dimension' not in df.columns and 'nombre_dimension' not in df.columns:
            print(f"Agregando columnas 'dimension' y 'nombre_dimension' al dataframe '{df_name}'")
            # Añadir las columnas con valores nulos inicialmente
            df['dimension'] = None
            df['nombre_dimension'] = None
            # Unir con el dataframe de referencia usando 'bpin' como llave
            dfs[df_name] = df.set_index('bpin').combine_first(reference_df).reset_index()
            print(f"Columnas 'dimension' y 'nombre_dimension' completadas en el dataframe '{df_name}'")
        elif 'dimension' not in df.columns:
            print(f"Agregando columna 'dimension' al dataframe '{df_name}'")
            df['dimension'] = None
            dfs[df_name] = df.set_index('bpin').combine_first(reference_df[['dimension']]).reset_index()
            print(f"Columna 'dimension' completada en el dataframe '{df_name}'")
        elif 'nombre_dimension' not in df.columns:
            print(f"Agregando columna 'nombre_dimension' al dataframe '{df_name}'")
            df['nombre_dimension'] = None
            dfs[df_name] = df.set_index('bpin').combine_first(reference_df[['nombre_dimension']]).reset_index()
            print(f"Columna 'nombre_dimension' completada en el dataframe '{df_name}'")
        else:
            print(f"Las columnas 'dimension' y 'nombre_dimension' ya existen en el dataframe '{df_name}'.")

# Optional: Display the columns after the operation
print("\nUnified table of all columns after adding/completing 'dimension' and 'nombre_dimension':")
all_columns_after = {}
for df_name, df in dfs.items():
  all_columns_after[df_name] = df.columns.tolist()

max_cols_after = max(len(cols) for cols in all_columns_after.values())

padded_columns_data_after = {}
for df_name, cols in all_columns_after.items():
  padded_columns_data_after[df_name] = cols + [None] * (max_cols_after - len(cols))

columns_df_after = pd.DataFrame(padded_columns_data_after)
print(columns_df_after)

# Crear un dataframe de referencia con las columnas 'bpin', 'linea_estrategica' y 'nombre_linea_estrategica'
reference_df_linea = None
for df in dfs.values():
    if 'bpin' in df.columns and 'linea_estrategica' in df.columns and 'nombre_linea_estrategica' in df.columns:
        # Ensure 'linea_estrategica' is string before dropping duplicates
        df['linea_estrategica'] = df['linea_estrategica'].astype(str)
        reference_df_linea = df[['bpin', 'linea_estrategica', 'nombre_linea_estrategica']].drop_duplicates().dropna(subset=['bpin']).set_index('bpin')
        print("DataFrame de referencia para línea estratégica creado con éxito.")
        break

if reference_df_linea is None:
    print("No se encontró un dataframe con las columnas 'bpin', 'linea_estrategica' y 'nombre_linea_estrategica'. No se puede completar la tarea de línea estratégica.")
else:
    # Iterar sobre cada dataframe en dfs
    for df_name, df in dfs.items():
        print(f"Procesando dataframe: '{df_name}'")
        # Añadir las columnas si no existen
        if 'linea_estrategica' not in df.columns:
            print(f"Agregando columna 'linea_estrategica' al dataframe '{df_name}'")
            df['linea_estrategica'] = None
        if 'nombre_linea_estrategica' not in df.columns:
            print(f"Agregando columna 'nombre_linea_estrategica' al dataframe '{df_name}'")
            df['nombre_linea_estrategica'] = None

        # Unir con el dataframe de referencia usando 'bpin' como llave
        # Asegurarse de que 'bpin' es la columna a la que se hace referencia
        if 'bpin' in df.columns:
          df = df.set_index('bpin').combine_first(reference_df_linea).reset_index()
          print(f"Columnas 'linea_estrategica' y 'nombre_linea_estrategica' completadas en el dataframe '{df_name}'")

          # Eliminar ".0" de los valores numéricos en 'linea_estrategica'
          if 'linea_estrategica' in df.columns:
              # Convert to numeric, coercing errors to NaN
              df['linea_estrategica'] = pd.to_numeric(df['linea_estrategica'], errors='coerce')
              # Convert to integer, then to string, handling NaN
              df['linea_estrategica'] = df['linea_estrategica'].dropna().astype(int).astype(str).reindex(df.index)
              # Fill NaN with original non-numeric values if any, or empty string
              df['linea_estrategica'] = df['linea_estrategica'].fillna('')
              print(f"Eliminado '.0' de los valores numéricos en 'linea_estrategica' del dataframe '{df_name}'")
          else:
              print(f"La columna 'linea_estrategica' no existe en el dataframe '{df_name}' después de la combinación.")

          dfs[df_name] = df # Update the dataframe in the dictionary
        else:
          print(f"La columna 'bpin' no se encontró en el dataframe '{df_name}'. No se pudo completar 'linea_estrategica' ni 'nombre_linea_estrategica'.")

print("\nProceso completado para todas las dataframes en 'dfs'.")

# Optional: Display the columns after the operation for verification
print("\nUnified table of all columns after adding/completing 'linea_estrategica' and 'nombre_linea_estrategica':")
all_columns_after_linea = {}
for df_name, df in dfs.items():
  all_columns_after_linea[df_name] = df.columns.tolist()

max_cols_after_linea = max(len(cols) for cols in all_columns_after_linea.values())

padded_columns_data_after_linea = {}
for df_name, cols in all_columns_after_linea.items():
  padded_columns_data_after_linea[df_name] = cols + [None] * (max_cols_after_linea - len(cols))

columns_df_after_linea = pd.DataFrame(padded_columns_data_after_linea)
print(columns_df_after_linea)

# Crear un dataframe de referencia con las columnas 'centro_gestor' y 'nombre_centro_gestor'
reference_df_centro_gestor = None
for df in dfs.values():
    if 'centro_gestor' in df.columns and 'nombre_centro_gestor' in df.columns:
        # Ensure 'centro_gestor' is string before dropping duplicates
        df['centro_gestor'] = df['centro_gestor'].astype(str)
        reference_df_centro_gestor = df[['centro_gestor', 'nombre_centro_gestor']].drop_duplicates().dropna(subset=['centro_gestor']).set_index('centro_gestor')
        print("DataFrame de referencia para centro gestor creado con éxito.")
        break

if reference_df_centro_gestor is None:
    print("No se encontró un dataframe con las columnas 'centro_gestor' y 'nombre_centro_gestor'. No se puede completar la tarea de centro gestor.")
else:
    # Iterar sobre el dataframe 'EJECUCION_NOVIEMBRE_2024'
    df_name = 'EJECUCION_NOVIEMBRE_2024'
    if df_name in dfs:
        df = dfs[df_name]
        print(f"Procesando dataframe: '{df_name}'")

        # Añadir la columna 'nombre_centro_gestor' si no existe
        if 'nombre_centro_gestor' not in df.columns:
            print(f"Agregando columna 'nombre_centro_gestor' al dataframe '{df_name}'")
            df['nombre_centro_gestor'] = None

        # Asegurarse de que 'centro_gestor' es la columna a la que se hace referencia y convertir a string
        if 'centro_gestor' in df.columns:
            df['centro_gestor'] = df['centro_gestor'].astype(str)
            # Unir con el dataframe de referencia usando 'centro_gestor' como llave
            df = df.set_index('centro_gestor').combine_first(reference_df_centro_gestor).reset_index()
            print(f"Columna 'nombre_centro_gestor' completada en el dataframe '{df_name}'")
            dfs[df_name] = df # Update the dataframe in the dictionary
        else:
            print(f"La columna 'centro_gestor' no se encontró en el dataframe '{df_name}'. No se pudo completar 'nombre_centro_gestor'.")
    else:
        print(f"El dataframe '{df_name}' no se encontró en 'dfs'.")

print("\nProceso completado para el dataframe 'EJECUCION_NOVIEMBRE_2024'.")

# Optional: Display the columns after the operation for verification
print("\nUnified table of all columns after adding/completing 'nombre_centro_gestor':")
all_columns_after_centro_gestor = {}
for df_name, df in dfs.items():
  all_columns_after_centro_gestor[df_name] = df.columns.tolist()

max_cols_after_centro_gestor = max(len(cols) for cols in all_columns_after_centro_gestor.values())

padded_columns_data_after_centro_gestor = {}
for df_name, cols in all_columns_after_centro_gestor.items():
  padded_columns_data_after_centro_gestor[df_name] = cols + [None] * (max_cols_after_centro_gestor - len(cols))

columns_df_after_centro_gestor = pd.DataFrame(padded_columns_data_after_centro_gestor)
columns_df_after_centro_gestor

"""## AÑADIR DATA ADICIONAL OPERATIVA

### APLICAR AÑOS A CADA DATAFRAME EN dfs
"""

dfs['EJECUCION_ENERO_2024']['anio'] = 2024
dfs['EJECUCION_FEBRERO_2024']['anio'] = 2024
dfs['EJECUCION_MARZO_2024']['anio'] = 2024
dfs['EJECUCION_ABRIL_2024']['anio'] = 2024
dfs['EJECUCION_MAYO_2024']['anio'] = 2024
dfs['EJECUCION_JUNIO_2024']['anio'] = 2024
dfs['EJECUCION_JULIO_2024']['anio'] = 2024
dfs['EJECUCION_AGOSTO_2024']['anio'] = 2024
dfs['EJECUCION_SEPTIEMBRE_2024']['anio'] = 2024
dfs['EJECUCION_OCTUBRE_2024']['anio'] = 2024
dfs['EJECUCION_NOVIEMBRE_2024']['anio'] = 2024
dfs['EJECUCION_DICIEMBRE_2024']['anio'] = 2024
dfs['EJECUCION_ENERO_2025']['anio'] = 2025
dfs['EJECUCION_FEBRERO_2025']['anio'] = 2025
dfs['EJECUCION_MARZO_2025']['anio'] = 2025
dfs['EJECUCION_ABRIL_2025']['anio'] = 2025
dfs['EJECUCION_MAYO_2025']['anio'] = 2025

"""### APLICAR dataframe_origen A CADA DATAFRAME EN dfs"""

dfs['EJECUCION_ENERO_2024']['dataframe_origen'] = 'EJECUCION_ENERO_2024'
dfs['EJECUCION_FEBRERO_2024']['dataframe_origen'] = 'EJECUCION_FEBRERO_2024'
dfs['EJECUCION_MARZO_2024']['dataframe_origen'] = 'EJECUCION_MARZO_2024'
dfs['EJECUCION_ABRIL_2024']['dataframe_origen'] = 'EJECUCION_ABRIL_2024'
dfs['EJECUCION_MAYO_2024']['dataframe_origen'] = 'EJECUCION_MAYO_2024'
dfs['EJECUCION_JUNIO_2024']['dataframe_origen'] = 'EJECUCION_JUNIO_2024'
dfs['EJECUCION_JULIO_2024']['dataframe_origen'] = 'EJECUCION_JULIO_2024'
dfs['EJECUCION_AGOSTO_2024']['dataframe_origen'] = 'EJECUCION_AGOSTO_2024'
dfs['EJECUCION_SEPTIEMBRE_2024']['dataframe_origen'] = 'EJECUCION_SEPTIEMBRE_2024'
dfs['EJECUCION_OCTUBRE_2024']['dataframe_origen'] = 'EJECUCION_OCTUBRE_2024'
dfs['EJECUCION_NOVIEMBRE_2024']['dataframe_origen'] = 'EJECUCION_NOVIEMBRE_2024'
dfs['EJECUCION_DICIEMBRE_2024']['dataframe_origen'] = 'EJECUCION_DICIEMBRE_2024'
dfs['EJECUCION_ENERO_2025']['dataframe_origen'] = 'EJECUCION_ENERO_2025'
dfs['EJECUCION_FEBRERO_2025']['dataframe_origen'] = 'EJECUCION_FEBRERO_2025'
dfs['EJECUCION_MARZO_2025']['dataframe_origen'] = 'EJECUCION_MARZO_2025'
dfs['EJECUCION_ABRIL_2025']['dataframe_origen'] = 'EJECUCION_ABRIL_2025'
dfs['EJECUCION_MAYO_2025']['dataframe_origen'] = 'EJECUCION_MAYO_2025'

"""## CREACIÓN DE DATAFRAME CONSOLIDADO"""

dfs['EJECUCION_ENERO_2024'].columns

# prompt: combina verticalmente todos los dataframes en dfs poniendo en primer lugar las variables numericas, comenzando por "bp", "bpin", en tercero lugar "nombre_proyecto" y ya luego el resto

# Identificar columnas numéricas
numeric_cols = ['bp', 'bpin'] # Inicialmente con 'bp' y 'bpin'

# Identificar la columna de nombre de proyecto
proyecto_col = 'nombre_proyecto'

# Identificar el resto de las columnas
other_cols_order = []

# Consolidar todos los dataframes
all_dfs_list = []
for df_name, df in dfs.items():
    # Asegurarse de que todas las columnas necesarias existen, si no, agregarlas con None
    current_cols = df.columns.tolist()
    required_cols = numeric_cols + [proyecto_col]

    for col in required_cols:
        if col not in current_cols:
            df[col] = None
            print(f"Agregando columna '{col}' al dataframe '{df_name}'")

    # Identificar el resto de las columnas para este dataframe
    current_other_cols = [col for col in current_cols if col not in required_cols]

    # Actualizar la lista global de otras columnas manteniendo el orden de aparición
    for col in current_other_cols:
        if col not in other_cols_order:
            other_cols_order.append(col)

    # Reorganizar las columnas del dataframe actual
    # Asegurarse de que todas las columnas en other_cols_order están presentes
    for col in other_cols_order:
        if col not in df.columns:
            df[col] = None

    # Definir el orden final de las columnas para este dataframe
    final_column_order = numeric_cols + [proyecto_col] + other_cols_order

    # Reindexar el dataframe para aplicar el orden
    df = df.reindex(columns=final_column_order)

    all_dfs_list.append(df)

# Concatenar todos los dataframes en el orden especificado
df_consolidado = pd.concat(all_dfs_list, ignore_index=True)

print("Dataframes combinados verticalmente en 'df_consolidado' con el orden de columnas especificado.")
print(df_consolidado.head())
print("\nColumnas del dataframe consolidado:")
print(df_consolidado.columns)
print("\nForma del dataframe consolidado:")
df_consolidado.shape

# Columnas a eliminar
columns_to_drop = ['rubro','producto_cuipo', 'producto_mga','nombre_reto', 'proposito','nombre_proposito', 'reto','nombre_producto_mga','codigo_producto_mga']

# Iterar sobre las columnas a eliminar
for col in columns_to_drop:
    # Verificar si la columna existe en el dataframe consolidado
    if col in df_consolidado.columns:
        # Eliminar la columna si existe
        df_consolidado = df_consolidado.drop(columns=[col])
        print(f"Columna '{col}' eliminada del dataframe 'df_consolidado'.")
    else:
        print(f"Columna '{col}' no encontrada en el dataframe 'df_consolidado'.")

# Opcional: Mostrar las columnas restantes del dataframe consolidado
print("\nColumnas restantes en el dataframe consolidado:")
df_consolidado.columns

df_consolidado.head()

# prompt: crear una columna llamada "periodo" en df_consolidado que combine el mes que obtendrá de la columna "dataframe_origen" según el texto de allí y crear una fecha mes/año usando un formato legible por looker studio ubicando el último día de cada mes, usando el estandar ISO 8601

from datetime import datetime
from dateutil.relativedelta import relativedelta

def obtener_fecha_fin_mes_desde_dataframe_origen_iso(df_origen, anio):
    """
    Extrae el mes de la cadena en la columna 'dataframe_origen' y combina con el año
    para obtener la fecha del último día de ese mes, formateada en ISO 8601 (YYYY-MM-DD).
    Asume el formato 'EJECUCION_MES_AÑO'.
    """
    if pd.isna(df_origen) or pd.isna(anio):
        return None

    partes = df_origen.split('_')
    if len(partes) > 1:
        mes_str = partes[1]
        mes_map = {
            'ENERO': 1, 'FEBRERO': 2, 'MARZO': 3, 'ABRIL': 4,
            'MAYO': 5, 'JUNIO': 6, 'JULIO': 7, 'AGOSTO': 8,
            'SEPTIEMBRE': 9, 'OCTUBRE': 10, 'NOVIEMBRE': 11, 'DICIEMBRE': 12
        }
        mes = mes_map.get(mes_str.upper())

        if mes is not None:
            try:
                # Crear el primer día del mes
                first_day_of_month = datetime(int(anio), mes, 1)
                # Obtener el último día del mes
                last_day_of_month = first_day_of_month + relativedelta(months=1) - relativedelta(days=1)
                # Formatear como YYYY-MM-DD (ISO 8601)
                return last_day_of_month.strftime('%Y-%m-%d')
            except ValueError:
                return None
    return None

# Asegurarse de que la columna 'anio' existe y es numérica o convertible
if 'anio' in df_consolidado.columns:
    # Convertir 'anio' a tipo entero, manejando posibles errores con NaNs
    df_consolidado['anio'] = pd.to_numeric(df_consolidado['anio'], errors='coerce').astype('Int64')

    # Crear la columna 'periodo' aplicando la función a 'dataframe_origen' y 'anio'
    df_consolidado['periodo'] = df_consolidado.apply(
        lambda row: obtener_fecha_fin_mes_desde_dataframe_origen_iso(row['dataframe_origen'], row['anio']),
        axis=1
    )

    print("\nColumna 'periodo' creada en df_consolidado con el último día del mes en formato ISO 8601.")
    print(df_consolidado[['dataframe_origen', 'periodo', 'anio']].head())
else:
    print("\nLa columna 'anio' no se encontró en 'df_consolidado'. No se puede crear la columna 'periodo'.")

# Optional: Mostrar las columnas restantes del dataframe consolidado
print("\nColumnas en el dataframe consolidado después de crear 'periodo':")
df_consolidado.columns

# Crear un dataframe de referencia con las columnas 'bpin', 'nombre_linea_estrategica' y 'linea_estrategica'
# Se crea este dataframe de referencia antes de llenar los nulos en el dataframe consolidado
reference_df_linea_consolidado = None
if 'bpin' in df_consolidado.columns and 'linea_estrategica' in df_consolidado.columns and 'nombre_linea_estrategica' in df_consolidado.columns:
    # Ensure 'linea_estrategica' is string before dropping duplicates
    df_consolidado['linea_estrategica'] = df_consolidado['linea_estrategica'].astype(str)
    reference_df_linea_consolidado = df_consolidado[['bpin', 'linea_estrategica', 'nombre_linea_estrategica']].drop_duplicates().dropna(subset=['bpin']).set_index('bpin')
    print("DataFrame de referencia para línea estratégica (consolidado) creado con éxito.")
else:
    print("No se encontraron las columnas 'bpin', 'linea_estrategica' y 'nombre_linea_estrategica' en el dataframe consolidado. No se puede crear el dataframe de referencia.")


if reference_df_linea_consolidado is not None:
    # Llenar los valores nulos en 'nombre_linea_estrategica' y 'linea_estrategica'
    # del dataframe consolidado usando el dataframe de referencia
    if 'bpin' in df_consolidado.columns:
        print("Llenando valores nulos en 'nombre_linea_estrategica' y 'linea_estrategica' del dataframe consolidado.")
        # Convertir 'bpin' en df_consolidado a string para la unión
        df_consolidado['bpin'] = df_consolidado['bpin'].astype(str)
        # Realizar el merge para llenar los nulos
        df_consolidado = df_consolidado.set_index('bpin').combine_first(reference_df_linea_consolidado).reset_index()
        print("Valores nulos en 'nombre_linea_estrategica' y 'linea_estrategica' completados en df_consolidado.")

        # Eliminar ".0" de los valores numéricos en 'linea_estrategica' después de la combinación
        if 'linea_estrategica' in df_consolidado.columns:
             # Convert to numeric, coercing errors to NaN
            df_consolidado['linea_estrategica'] = pd.to_numeric(df_consolidado['linea_estrategica'], errors='coerce')
            # Convert to integer, then to string, handling NaN
            df_consolidado['linea_estrategica'] = df_consolidado['linea_estrategica'].dropna().astype(int).astype(str).reindex(df_consolidado.index)
            # Fill NaN with original non-numeric values if any, or empty string
            df_consolidado['linea_estrategica'] = df_consolidado['linea_estrategica'].fillna('')
            print("Eliminado '.0' de los valores numéricos en 'linea_estrategica' del dataframe consolidado.")
    else:
        print("La columna 'bpin' no se encontró en el dataframe consolidado. No se pueden llenar los valores nulos.")

print("\nProceso completado para llenar 'nombre_linea_estrategica' y 'linea_estrategica' en el dataframe consolidado.")

# Optional: Display head and columns of the consolidated dataframe
print("\nPrimeras filas del dataframe consolidado después de llenar columnas de línea estratégica:")
print(df_consolidado[['bpin', 'linea_estrategica', 'nombre_linea_estrategica']].head())
print("\nColumnas del dataframe consolidado:")
df_consolidado.columns

"""## GENERACIÓN DE OUTPUT Y EXPORTACIÓN A .CSV DEL DATAFRAME CONSOLIDADO"""

df_consolidado

print(df_consolidado.isnull().sum())

# Calculate the percentage of null values for each row
null_percentage_per_row = df_consolidado.isnull().sum(axis=1) / df_consolidado.shape[1]

# Identify rows where more than 80% of columns are null
rows_to_drop_mask = null_percentage_per_row > 0.8

# Drop the identified rows from the DataFrame
df_consolidado = df_consolidado[~rows_to_drop_mask].copy()

print(f"Se eliminaron {rows_to_drop_mask.sum()} filas donde más del 80% de las columnas eran nulas.")
print("\nForma del dataframe consolidado después de la limpieza:")
df_consolidado.shape

# Verificar que la columna 'periodo' esté en formato ISO 8601
if 'periodo' in df_consolidado.columns:
    try:
        # Convertir la columna 'periodo' a tipo datetime para asegurar el formato
        df_consolidado['periodo'] = pd.to_datetime(df_consolidado['periodo'], format='%Y-%m-%d', errors='coerce')
        print("La columna 'periodo' está en formato ISO 8601 compatible con Looker Studio.")
    except Exception as e:
        print(f"Error al convertir la columna 'periodo' al formato ISO 8601: {e}")
else:
    print("La columna 'periodo' no existe en el dataframe consolidado.")

df_consolidado.to_csv('/content/drive/MyDrive/INPUTS_DASH/DASHBOARD_PROYECTOS/EJECUCION_PRESUPUESTAL_CONSOLIDADO/df_ejecucion_presupuestal_total.csv', index=False)
print("DataFrame 'df_ejecucion_presupuestal_total.csv' creado exitosamente en la carpeta '/content/drive/MyDrive/INPUTS_DASH/DASHBOARD_PROYECTOS/EJECUCION_PRESUPUESTAL_CONSOLIDADO'.")

search_string = "2019760010795"

# Buscar coincidencias en todas las columnas del dataframe consolidado
coincidences = df_consolidado[
    df_consolidado.astype(str).apply(lambda row: row.str.contains(search_string, na=False)).any(axis=1)
]

if not coincidences.empty:
    print(f"Se encontraron coincidencias para '{search_string}' en df_consolidado:")
    print(coincidences)
else:
    print(f"No se encontraron coincidencias para '{search_string}' en df_consolidado.")

coincidences[['bpin','nombre_centro_gestor', 'nombre_proyecto']].drop_duplicates()